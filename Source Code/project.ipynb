{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries \n",
    "import tensorflow.keras\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "import argparse\n",
    "import os\n",
    "import string\n",
    "import cv2 \n",
    "import os\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import eel\n",
    "from PIL import Image, ImageOps  \n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import imutils\n",
    "import time\n",
    "\n",
    "eel.init('site')\n",
    "                                     #Frames Creation\n",
    "                    \n",
    "def frame(cust):\n",
    "    # Read the video from specified path \n",
    "    #print(cust)\n",
    "    s=cust.split('\\\\')\n",
    "    ch=s[len(s)-1]\n",
    "    print(ch)\n",
    "    cam = cv2.VideoCapture(ch) \n",
    "    try: \n",
    "        # creating a folder named data \n",
    "        if not os.path.exists('data'): \n",
    "            os.makedirs('data') \n",
    "\n",
    "    # if not created then raise error \n",
    "    except OSError: \n",
    "        print ('Error: Creating directory of data') \n",
    "    # frame \n",
    "    currentframe = 0\n",
    "    while(True): \n",
    "        # reading from frame \n",
    "        ret,frame = cam.read()\n",
    "        if ret: \n",
    "            # if video is still left continue creating images \n",
    "            name = './data/frame' + str(currentframe) + '.jpg'\n",
    "            #print ('Creating...' + name) \n",
    "        # writing the extracted images \n",
    "            cv2.imwrite(name, frame) \n",
    "# increasing counter so that it will \n",
    "# show how many frames are created \n",
    "            currentframe += 1\n",
    "        else: \n",
    "            break\n",
    "# Release all space and windows once done \n",
    "    cam.release() \n",
    "    cv2.destroyAllWindows()                \n",
    "        \n",
    "                                                    #helmate Detection\n",
    "    \n",
    "@eel.expose                                             # Expose this function to Javascript\n",
    "def helmetDetect(cust):\n",
    "    frame(cust)\n",
    "# Disable scientific notation for clarity\n",
    "    np.set_printoptions(suppress=True)\n",
    "#Load the model\n",
    "    model = tensorflow.keras.models.load_model('keras_model.h5')\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "# Replace this with the path to your image\n",
    "    image = Image.open('data\\\\frame3.jpg')\n",
    "    #a=cv2.imread('data\\\\frame3.jpg')\n",
    "    #cv2.imshow(\"OriginalIamge\",a)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "# Make sure to resize all images to 224, 224 otherwise they won't fit in the array\n",
    "    image = image.resize((224, 224))\n",
    "    image_array = np.asarray(image)\n",
    "\n",
    "# Normalize the image\n",
    "    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "    data[0] = normalized_image_array\n",
    "#Run the interface\n",
    "    prediction = model.predict(data)\n",
    "    print(prediction)\n",
    "\n",
    "    result=prediction[0,1]\n",
    "    if result < 0.05:\n",
    "        print(\"Weraed Helmate\")\n",
    "        eel.my_helmet(0)\n",
    "    else:\n",
    "        print(\"Not Weraed Helmate\")\n",
    "        numberplate()\n",
    "        eel.my_helmet(1)\n",
    "    \n",
    "\n",
    "                                              #Triple seat\n",
    "@eel.expose                                             # Expose this function to Javascript            \n",
    "def tripleDetect(cust):\n",
    "    frame(cust)\n",
    "# Disable scientific notation for clarity\n",
    "    np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "    model = tensorflow.keras.models.load_model('keras_modeltriple.h5')\n",
    "\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "\n",
    "# Replace this with the path to your image\n",
    "    image = Image.open('data\\\\frame10.jpg')\n",
    "\n",
    "#resize the image to a 224x224 with the same strategy as in TM2:\n",
    "#resizing the image to be at least 224x224 and then cropping from the center\n",
    "    size = (224, 224)\n",
    "    image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "\n",
    "#turn the image into a numpy array\n",
    "    image_array = np.asarray(image)\n",
    "\n",
    "# display the resized image\n",
    "    #image.show()\n",
    "\n",
    "# Normalize the image\n",
    "    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "    data[0] = normalized_image_array\n",
    "\n",
    "# run the inference\n",
    "    prediction = model.predict(data)\n",
    "    result=prediction[0,1]\n",
    "    print(prediction)\n",
    "    if result < 0.005:\n",
    "        print(\"not Triple Seat\")\n",
    "        eel.my_triple(0)\n",
    "    else:\n",
    "        print(\"Triple Seat\")\n",
    "        numberplate()\n",
    "        eel.my_triple(1)\n",
    "\n",
    "                             #number plate Detection\n",
    "def numberplate():                                       \n",
    "        image = cv2.imread('data\\\\frame3.jpg')         #m2.mp4\n",
    "        #cv2.imshow(\"original\", image)\n",
    "        #cv2.waitKey(0)\n",
    "    \n",
    "    # crop the image using array slices -- it's a NumPy array\n",
    "        cropped = image[780:900, 760:950]        \n",
    "        #cv2.imshow(\"cropped\", cropped)\n",
    "        cv2.imwrite(\"crop.png\", cropped)\n",
    "        #cv2.waitKey(0)\n",
    "    \n",
    "    # load the example image and convert it to grayscale\n",
    "        image = cv2.imread(\"crop.jpg\")\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # we should apply thresholding to preprocess the image\n",
    "        preprocess = \"thresh\"\n",
    "        gray = cv2.threshold(gray, 0, 255,\n",
    "                cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    " \n",
    "     # write the grayscale image to disk as a temporary file so we can apply OCR to it\n",
    "        filename = \"{}.png\".format(os.getpid())\n",
    "        cv2.imwrite(filename, gray)\n",
    "    \n",
    "        pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "    # load the image as a PIL/Pillow image, apply OCR, and then delete the temporary file\n",
    "        text = pytesseract.image_to_string(Image.open(filename))\n",
    "        os.remove(filename)\n",
    "    # show the output images\n",
    "        #cv2.imshow(\"Image\", image)\n",
    "        #cv2.imshow(\"Output\", gray)\n",
    "    \n",
    "        file = open(\"file.txt\", 'r')\n",
    "        lines = file.readlines()\n",
    "        file.close()\n",
    "    \n",
    "    #remove space and newline from string\n",
    "        lis=(text.strip()).split()\n",
    "        st1=\"\".join(lis)\n",
    "        print(\"Number Plate \"+st1)\n",
    "\n",
    "        for line in lines:\n",
    "            parts = line.split() # split line into parts\n",
    "            if len(parts) > 1:\n",
    "                column1 = parts[0]\n",
    "                if column1==st1:\n",
    "                    column2 = parts[1]\n",
    "                    print(\"Mobile Number \"+column2)\n",
    "                \n",
    "                                                    #SMS Module\n",
    "        \n",
    "        def sendSMS(apikey, numbers, sender, message):\n",
    "            params = {'apikey':apikey , 'numbers': numbers,'sender': sender, 'message' : message}\n",
    "            f = urllib.request.urlopen('https://api.textlocal.in/send/?'\n",
    "                + urllib.parse.urlencode(params))\n",
    "            return (f.read(), f.code)\n",
    "  \n",
    "        APIKEY='vS5w1xFYmOU-u2ak0YfXREulHMgkgY9d6B9ea6UuSP'\n",
    "        resp, code = sendSMS(APIKEY, '123456786','TXTLCL', 'You are voilated the traffic rule ')\n",
    "        print (resp)\n",
    "        \n",
    "                                            #sign Detection\n",
    "@eel.expose \n",
    "def signDetect(cust):\n",
    "    def decode_predictions(scores, geometry):\n",
    "    # grab the number of rows and columns from the scores volume, then\n",
    "    # initialize our set of bounding box rectangles and corresponding\n",
    "    # confidence scores\n",
    "        (numRows, numCols) = scores.shape[2:4]\n",
    "        rects = []\n",
    "        confidences = []\n",
    " \n",
    "    # loop over the number of rows\n",
    "        for y in range(0, numRows):\n",
    "        # extract the scores (probabilities), followed by the\n",
    "        # geometrical data used to derive potential bounding box\n",
    "        # coordinates that surround text\n",
    "            scoresData = scores[0, 0, y]\n",
    "            xData0 = geometry[0, 0, y]\n",
    "            xData1 = geometry[0, 1, y]\n",
    "            xData2 = geometry[0, 2, y]\n",
    "            xData3 = geometry[0, 3, y]\n",
    "            anglesData = geometry[0, 4, y]\n",
    " \n",
    "        # loop over the number of columns\n",
    "            for x in range(0, numCols):\n",
    "            # if our score does not have sufficient probability,\n",
    "            # ignore it\n",
    "                if scoresData[x] < confidence:\n",
    "                    continue\n",
    " \n",
    "            # compute the offset factor as our resulting feature\n",
    "            # maps will be 4x smaller than the input image\n",
    "                (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    " \n",
    "            # extract the rotation angle for the prediction and\n",
    "            # then compute the sin and cosine\n",
    "                angle = anglesData[x]\n",
    "                cos = np.cos(angle)\n",
    "                sin = np.sin(angle)\n",
    " \n",
    "            # use the geometry volume to derive the width and height\n",
    "            # of the bounding box\n",
    "                h = xData0[x] + xData2[x]\n",
    "                w = xData1[x] + xData3[x]\n",
    " \n",
    "            # compute both the starting and ending (x, y)-coordinates\n",
    "            # for the text prediction bounding box\n",
    "                endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "                endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "                startX = int(endX - w)\n",
    "                startY = int(endY - h)\n",
    " \n",
    "            # add the bounding box coordinates and probability score\n",
    "            # to our respective lists\n",
    "                rects.append((startX, startY, endX, endY))\n",
    "                confidences.append(scoresData[x])\n",
    " \n",
    "    # return a tuple of the bounding boxes and associated confidences\n",
    "        return (rects, confidences)\n",
    "    east=\"frozen_east_text_detection.pb\"\n",
    "    #print(cust)\n",
    "    s=cust.split('\\\\')\n",
    "    ch=s[len(s)-1]\n",
    "    print(ch)\n",
    "    video=ch\n",
    "    confidence=0.5\n",
    "    width=320\n",
    "    height=320\n",
    "\n",
    "    (W, H) = (None, None)\n",
    "    (newW, newH) = (width, height)\n",
    "    (rW, rH) = (None, None)\n",
    " \n",
    "    # define the two output layer names for the EAST detector model that\n",
    "# we are interested -- the first is the output probabilities and the\n",
    "# second can be used to derive the bounding box coordinates of text\n",
    "    layerNames = [\n",
    "        \"feature_fusion/Conv_7/Sigmoid\",\n",
    "        \"feature_fusion/concat_3\"]\n",
    " \n",
    "    # load the pre-trained EAST text detector\n",
    "    print(\"[INFO] loading EAST text detector...\")\n",
    "    net = cv2.dnn.readNet(east)\n",
    " #  grab a reference to the video file\n",
    "    vs = cv2.VideoCapture(video)\n",
    " \n",
    " # start the FPS throughput estimator\n",
    "    fps = FPS().start()\n",
    "# loop over frames from the video stream\n",
    "    while True:\n",
    "    # grab the current frame, then handle if we are using a\n",
    "    # VideoStream or VideoCapture object\n",
    "        frame = vs.read()\n",
    "        frame = frame[1] \n",
    "    # check to see if we have reached the end of the stream\n",
    "        if frame is None:\n",
    "            break\n",
    " \n",
    "    # resize the frame, maintaining the aspect ratio\n",
    "        frame = imutils.resize(frame, width=1000)\n",
    "        orig = frame.copy()\n",
    " \n",
    "    # if our frame dimensions are None, we still need to compute the\n",
    "    # ratio of old frame dimensions to new frame dimensions\n",
    "        if W is None or H is None:\n",
    "            (H, W) = frame.shape[:2]\n",
    "            rW = W / float(newW)\n",
    "            rH = H / float(newH)\n",
    " \n",
    "    # resize the frame, this time ignoring aspect ratio\n",
    "        frame = cv2.resize(frame, (newW, newH))\n",
    "# construct a blob from the frame and then perform a forward pass\n",
    "    # of the model to obtain the two output layer sets\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1.0, (newW, newH),\n",
    "            (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        (scores, geometry) = net.forward(layerNames)\n",
    " \n",
    "    # decode the predictions, then  apply non-maxima suppression to\n",
    "    # suppress weak, overlapping bounding boxes\n",
    "        (rects, confidences) = decode_predictions(scores, geometry)\n",
    "        boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    " \n",
    "    # loop over the bounding boxes\n",
    "        for (startX, startY, endX, endY) in boxes:\n",
    "        # scale the bounding box coordinates based on the respective\n",
    "        # ratios\n",
    "            startX = int(startX * rW)\n",
    "            startY = int(startY * rH)\n",
    "            endX = int(endX * rW)\n",
    "            endY = int(endY * rH)\n",
    " \n",
    "        # draw the bounding box on the frame\n",
    "            cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "# update the FPS counter\n",
    "        fps.update()\n",
    " \n",
    "    # show the output frame\n",
    "        cv2.imshow(\"Text Detection\", orig)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "    # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    " \n",
    " # stop the timer and display FPS information\n",
    "    fps.stop()\n",
    "    print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "    print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    " \n",
    " # orelease the file pointer\n",
    "    vs.release()\n",
    " \n",
    " # close all windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "eel.start('index.html')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
